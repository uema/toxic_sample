{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# このノートについて\n",
    "\n",
    "## 目的\n",
    "* とりあえず提出してみて課題の感じをつかむ\n",
    "\n",
    "## 流れ\n",
    "* ライブラリをインポート\n",
    "* 学習・予測に使うデータを取得\n",
    "* 特徴エンジニアリング(テキストクリーニング)\n",
    "* 学習・予測・提出\n",
    "\n",
    "## 参考\n",
    "\n",
    "* データの分析およびクリーニングについて\n",
    "    * jagan, Stop the S@#$ - Toxic Comments EDA, https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda\n",
    "        * ほとんどこの人のやり方をパクった\n",
    "* モデル構築\n",
    "    * Bojan Tunguz, Logistic regression with words and char n-grams, https://www.kaggle.com/tunguz/logistic-regression-with-words-and-char-n-grams/code\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# いつもの\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "\n",
    "# FeatureEngineering\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# データのパスなど\n",
    "home_dir=os.path.dirname(os.getcwd())\n",
    "data_dir=os.path.join(home_dir, \"data\")\n",
    "result_dir=os.path.join(home_dir, \"result\")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コーパスをダウンロード\n",
    "* wordnetはレンマ化のため, stopwordsはストップワードのためにダウンロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習・予測に使うデータを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               0\n",
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = os.path.join(data_dir, \"train.csv\") \n",
    "train_df = pd.read_csv(train_path)\n",
    "print(train_df.isnull().sum())\n",
    "train_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "comment_text    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>Please do not add nonsense to Wikipedia. Such ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>\" \\n Only a fool can believe in such numbers. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>== Double Redirects == \\n\\n When fixing double...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
       "5  0001ea8717f6de06  Thank you for understanding. I think very high...\n",
       "6  00024115d4cbde0f  Please do not add nonsense to Wikipedia. Such ...\n",
       "7  000247e83dcc1211                   :Dear god this site is horrible.\n",
       "8  00025358d4737918  \" \\n Only a fool can believe in such numbers. ...\n",
       "9  00026d1092fe71cc  == Double Redirects == \\n\\n When fixing double..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = os.path.join(data_dir, \"test.csv\") \n",
    "test_df = pd.read_csv(test_path)\n",
    "print(test_df.isnull().sum())\n",
    "test_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12    0.5           0.5      0.5     0.5     0.5   \n",
       "1  0000247867823ef7    0.5           0.5      0.5     0.5     0.5   \n",
       "2  00013b17ad220c46    0.5           0.5      0.5     0.5     0.5   \n",
       "3  00017563c3f7919a    0.5           0.5      0.5     0.5     0.5   \n",
       "4  00017695ad8997eb    0.5           0.5      0.5     0.5     0.5   \n",
       "5  0001ea8717f6de06    0.5           0.5      0.5     0.5     0.5   \n",
       "6  00024115d4cbde0f    0.5           0.5      0.5     0.5     0.5   \n",
       "7  000247e83dcc1211    0.5           0.5      0.5     0.5     0.5   \n",
       "8  00025358d4737918    0.5           0.5      0.5     0.5     0.5   \n",
       "9  00026d1092fe71cc    0.5           0.5      0.5     0.5     0.5   \n",
       "\n",
       "   identity_hate  \n",
       "0            0.5  \n",
       "1            0.5  \n",
       "2            0.5  \n",
       "3            0.5  \n",
       "4            0.5  \n",
       "5            0.5  \n",
       "6            0.5  \n",
       "7            0.5  \n",
       "8            0.5  \n",
       "9            0.5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_path = os.path.join(data_dir, \"sample_submission.csv\")\n",
    "submit_df = pd.read_csv(submit_path)\n",
    "submit_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴エンジニアリング\n",
    "## テキストクリーニング "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/0B1yuv8YaUVlZZ1RzMFJmc1ZsQmM/view\n",
    "# Aphost lookup dict\n",
    "APPO = {\n",
    "    \"aren't\" : \"are not\",\n",
    "    \"can't\" : \"cannot\",\n",
    "    \"couldn't\" : \"could not\",\n",
    "    \"didn't\" : \"did not\",\n",
    "    \"doesn't\" : \"does not\",\n",
    "    \"don't\" : \"do not\",\n",
    "    \"hadn't\" : \"had not\",\n",
    "    \"hasn't\" : \"has not\",\n",
    "    \"haven't\" : \"have not\",\n",
    "    \"he'd\" : \"he would\",\n",
    "    \"he'll\" : \"he will\",\n",
    "    \"he's\" : \"he is\",\n",
    "    \"i'd\" : \"I would\",\n",
    "    \"i'd\" : \"I had\",\n",
    "    \"i'll\" : \"I will\",\n",
    "    \"i'm\" : \"I am\",\n",
    "    \"isn't\" : \"is not\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"it'll\":\"it will\",\n",
    "    \"i've\" : \"I have\",\n",
    "    \"let's\" : \"let us\",\n",
    "    \"mightn't\" : \"might not\",\n",
    "    \"mustn't\" : \"must not\",\n",
    "    \"shan't\" : \"shall not\",\n",
    "    \"she'd\" : \"she would\",\n",
    "    \"she'll\" : \"she will\",\n",
    "    \"she's\" : \"she is\",\n",
    "    \"shouldn't\" : \"should not\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"there's\" : \"there is\",\n",
    "    \"they'd\" : \"they would\",\n",
    "    \"they'll\" : \"they will\",\n",
    "    \"they're\" : \"they are\",\n",
    "    \"they've\" : \"they have\",\n",
    "    \"we'd\" : \"we would\",\n",
    "    \"we're\" : \"we are\",\n",
    "    \"weren't\" : \"were not\",\n",
    "    \"we've\" : \"we have\",\n",
    "    \"what'll\" : \"what will\",\n",
    "    \"what're\" : \"what are\",\n",
    "    \"what's\" : \"what is\",\n",
    "    \"what've\" : \"what have\",\n",
    "    \"where's\" : \"where is\",\n",
    "    \"who'd\" : \"who would\",\n",
    "    \"who'll\" : \"who will\",\n",
    "    \"who're\" : \"who are\",\n",
    "    \"who's\" : \"who is\",\n",
    "    \"who've\" : \"who have\",\n",
    "    \"won't\" : \"will not\",\n",
    "    \"wouldn't\" : \"would not\",\n",
    "    \"you'd\" : \"you would\",\n",
    "    \"you'll\" : \"you will\",\n",
    "    \"you're\" : \"you are\",\n",
    "    \"you've\" : \"you have\",\n",
    "    \"'re\": \" are\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'll\":\" will\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"tryin'\":\"trying\",\n",
    "    \"&\": \" and \",\n",
    "    \"@\": \" at \",\n",
    "    \"0\": \" zero \",\n",
    "    \"1\": \" one \",\n",
    "    \"2\": \" two \",\n",
    "    \"3\": \" three \",\n",
    "    \"4\": \" four \",\n",
    "    \"5\": \" five \",\n",
    "    \"6\": \" six \",\n",
    "    \"7\": \" seven \",\n",
    "    \"8\": \" eight \",\n",
    "    \"9\": \" nine \"\n",
    "}\n",
    "tokenizer=TweetTokenizer()\n",
    "lem = WordNetLemmatizer()\n",
    "eng_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(comment):\n",
    "    # 大文字->小文字に変換\n",
    "    comment = comment.lower()\n",
    "    # ipとユーザを除く\n",
    "    comment = re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.d{,3}\", \"\", comment)\n",
    "    comment = re.sub(\"\\[\\[.\\]]\", \"\", comment)\n",
    "    # 連結している記号を分離 (\"!!\" -> \"! !\")\n",
    "    comment = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' \\1 ', comment)\n",
    "    # 数字を分離(\"2018\" -> \"2 0 1 8\")\n",
    "    comment = re.sub(r'([0-9*])', r' \\1 ', comment)\n",
    "    # 特殊記号を削除\n",
    "    comment = re.sub(r'([\\;\\:\\|•«=\\n])', ' ', comment)    \n",
    "    # 文章を単語の配列にする\n",
    "    words = tokenizer.tokenize(comment)\n",
    "    # 略語を戻す\n",
    "    words = [APPO[word] if word in APPO else word for word in words]\n",
    "    # レンマ化(例:databases -> database等)\n",
    "    words = [lem.lemmatize(word, \"v\") for word in words]\n",
    "    # ストップワードを除去(例 are, by 等)\n",
    "    words = [w for w in words if not w in eng_stopwords]\n",
    "    # 配列になった単語列を繋げ直して文章化\n",
    "    clean_sent=\" \".join(words)\n",
    "    clean_sent = re.sub(r'([\\'])', ' ', clean_sent)\n",
    "    return clean_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----before----\n",
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "----after----\n",
      "explanation edit make username hardcore metallica fan revert ?   vandalisms , closure gas vote new york dolls fac . please   remove template talk page since   retire .  two   seven \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test  two   zero   zero   nine '"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_idx = 0\n",
    "print(\"----before----\")\n",
    "print(train_df[\"comment_text\"][comment_idx])\n",
    "print(\"----after----\")\n",
    "print(clean(train_df[\"comment_text\"][comment_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation edit make username hardcore metall...\n",
       "1           aww ! match background colour   seemingly st...\n",
       "2         hey man ,   really try edit war .   guy consta...\n",
       "3         \"   make real suggestions improvement - wonder...\n",
       "4                   , sir , hero . chance remember page   ?\n",
       "5         \" congratulations well , use tool well . · talk \"\n",
       "6                               cocksucker piss around work\n",
       "7         vandalism matt shirvington article revert . pl...\n",
       "8         sorry word   nonsense   offensive . anyway ,  ...\n",
       "9                      alignment subject contrary dulithgow\n",
       "10        \" fair use rationale image wonju . jpg thank u...\n",
       "11                      bbq man let discuss - maybe phone ?\n",
       "12        hey .  .  . .  .  at  talk . .  .  . exclusive...\n",
       "13        start throw accusations warn , let review edit...\n",
       "14        oh , girl start arguments . stick nose   belon...\n",
       "                                ...                        \n",
       "159556                           irc , , specific request .\n",
       "159557    opinion happen - topic . believe never claim c...\n",
       "159558    please stop remove content wikipedia consider ...\n",
       "159559    image barack - obama - mother . jpg list delet...\n",
       "159560    \" edit article without consensus  and  removal...\n",
       "159561    \" , read ( would think everyone could recite h...\n",
       "159562    \" auto guide motor press good source encyclope...\n",
       "159563    \" please identify part blp apply blp clearly s...\n",
       "159564    catalan independentism social movement involve...\n",
       "159565    number parentheses additional decimal point me...\n",
       "159566    \" second time ask , view completely contradict...\n",
       "159567    ashamed horrible thing put talk page .  nine  ...\n",
       "159568    spitzer umm , theres actual article prostituti...\n",
       "159569    look like actually put speedy first version de...\n",
       "159570    \" .  .  . really   think understand . come ide...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train = train_df[\"comment_text\"]\n",
    "corpus_train = corpus_train.apply(lambda x:clean(x))\n",
    "corpus_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_test = test_df[\"comment_text\"]\n",
    "corpus_test = corpus_test.apply(lambda x:clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキストをBoW化\n",
    "### TfidfVectorizer\n",
    "* strip_accents ... unicode: アクセント記号の削除\n",
    "* ngram_range=(n_min, n_max) ...n-gram の指定 \n",
    "* max_features ... tfidfのスコアの上位いくつまで語彙を残すか指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=15000)\n",
    "X_train = vectorizer.fit_transform(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['TM',\n",
       " '__',\n",
       " '___',\n",
       " '_noticeboard',\n",
       " 'aa',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abbreviation',\n",
       " 'abc',\n",
       " 'abide',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'able edit',\n",
       " 'able find',\n",
       " 'able get',\n",
       " 'able help',\n",
       " 'able make',\n",
       " 'able see',\n",
       " 'abolish',\n",
       " 'abortion',\n",
       " 'abraham',\n",
       " 'abroad',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutely nothing',\n",
       " 'absorb']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))\n",
    "\n",
    "vectorizer.get_feature_names()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習&予測&提出\n",
    "## モデル\n",
    "* ロジスティック回帰(0~1)\n",
    "* カテゴリ('toxic', 'severe_toxic'等)についてそれぞれモデルを作成(計6個)し予測\n",
    "* 一応CVしておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_df.columns[2:].tolist()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9689649816587739\n",
      "CV score for class severe_toxic is 0.9845102846644188\n",
      "CV score for class obscene is 0.9842854110524597\n",
      "CV score for class threat is 0.9834109963254125\n",
      "CV score for class insult is 0.9751851202723028\n",
      "CV score for class identity_hate is 0.9735204222232172\n"
     ]
    }
   ],
   "source": [
    "for class_name in class_names:\n",
    "    y_train = train_df[class_name]\n",
    "    \n",
    "    classifier = LogisticRegression()\n",
    "    #classifier = RandomForestClassifier()\n",
    "    #classifier = SVC()\n",
    "\n",
    "    cv_loss = np.mean(cross_val_score(classifier, X_train, y_train, cv=5, scoring='roc_auc'))\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_loss))\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    submit_df[class_name] = classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>0.239051</td>\n",
       "      <td>0.996915</td>\n",
       "      <td>0.051012</td>\n",
       "      <td>0.958278</td>\n",
       "      <td>0.338641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.009816</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.008483</td>\n",
       "      <td>0.003472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.001265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.030232</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>0.001863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>0.001481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.001653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>0.540047</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.041849</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.117467</td>\n",
       "      <td>0.006196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>0.023410</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>0.011891</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>0.005727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.001385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.999177      0.239051  0.996915  0.051012  0.958278   \n",
       "1  0000247867823ef7  0.009816      0.003505  0.004842  0.001986  0.008483   \n",
       "2  00013b17ad220c46  0.005898      0.001192  0.003339  0.000509  0.003280   \n",
       "3  00017563c3f7919a  0.005910      0.002618  0.003964  0.001250  0.004519   \n",
       "4  00017695ad8997eb  0.030232      0.002802  0.008956  0.001256  0.014770   \n",
       "5  0001ea8717f6de06  0.009118      0.001530  0.004620  0.001020  0.008135   \n",
       "6  00024115d4cbde0f  0.006794      0.000948  0.004256  0.000615  0.006288   \n",
       "7  000247e83dcc1211  0.540047      0.004590  0.041849  0.003581  0.117467   \n",
       "8  00025358d4737918  0.023410      0.003529  0.011891  0.002299  0.015518   \n",
       "9  00026d1092fe71cc  0.004735      0.001052  0.003505  0.000798  0.004109   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.338641  \n",
       "1       0.003472  \n",
       "2       0.000800  \n",
       "3       0.001265  \n",
       "4       0.001863  \n",
       "5       0.001481  \n",
       "6       0.001653  \n",
       "7       0.006196  \n",
       "8       0.005727  \n",
       "9       0.001385  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df.to_csv(os.path.join(result_dir, \"tdidf_logistic.csv\"), index=False) \n",
    "\n",
    "submit_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# このチュートリアルをやれば、大体1600~1700位くらいになるはず(2600チーム中)!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## これから\n",
    "\n",
    "* いろんな特徴量をとる\n",
    "    * コメントの文字数, 顔文字, id\n",
    "* BoW以外で特徴抽出をやってみる\n",
    "    * http://catindog.hatenablog.com/entry/2017/03/31/221644\n",
    "    * fasttext https://www.kaggle.com/mschumacher/using-fasttext-models-for-robust-embeddings\n",
    "* 特徴量を圧縮する\n",
    "    * PCA, Topic Model, ...\n",
    "    * https://www.kaggle.com/jagangupta/understanding-the-topic-of-toxicity\n",
    "* いろんな学習モデルを使う\n",
    "    * https://www.kaggle.com/jhoward/improved-lstm-baseline-glove-dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
